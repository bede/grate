use crate::filter::{Buffers, ProcessingStats};
use crate::minimizers::KmerHasher;
use crate::{FixedRapidHasher, IndexConfig, RapidHashSet};
use anyhow::{Context, Result};
use bincode::serde::{decode_from_std_read, encode_into_std_write};
use paraseq::Record;
use paraseq::prelude::{ParallelProcessor, ParallelReader};
use parking_lot::Mutex;
use serde::{Deserialize, Serialize};
use std::fs::File;
use std::io::{self, BufReader, BufWriter, Read, Write};
use std::path::{Path, PathBuf};
use std::sync::{Arc, OnceLock};
use std::time::Instant;

/// Serialisable header for the index file
#[derive(Serialize, Deserialize, Debug)]
pub struct IndexHeader {
    pub format_version: u8,
    pub kmer_length: u8,
    pub window_size: u8,
}

impl IndexHeader {
    pub fn new(kmer_length: u8, window_size: u8) -> Self {
        IndexHeader {
            format_version: 3,
            kmer_length,
            window_size,
        }
    }

    /// Validate header
    pub fn validate(&self) -> anyhow::Result<()> {
        if self.format_version != 3 {
            return Err(anyhow::anyhow!(
                "Unsupported index format version: {}",
                self.format_version
            ));
        }

        Ok(())
    }

    /// Get k
    pub fn kmer_length(&self) -> u8 {
        self.kmer_length
    }

    /// Get w
    pub fn window_size(&self) -> u8 {
        self.window_size
    }
}

/// Load just the header and count from an index file
pub fn load_header_and_count<P: AsRef<Path>>(path: &P) -> Result<(IndexHeader, usize)> {
    let file =
        File::open(path).context(format!("Failed to open index file {:?}", path.as_ref()))?;
    let mut reader = BufReader::new(file);

    // Deserialise header
    let header: IndexHeader = decode_from_std_read(&mut reader, bincode::config::standard())
        .context("Failed to deserialise index header")?;
    header.validate()?;

    // Deserialise the count of minimizers
    let count: usize = decode_from_std_read(&mut reader, bincode::config::standard())
        .context("Failed to deserialise minimizer count")?;

    Ok((header, count))
}

static INDEX: OnceLock<(PathBuf, crate::MinimizerSet, IndexHeader)> = OnceLock::new();

pub fn load_minimizers_cached(
    path: &Path,
) -> Result<(&'static crate::MinimizerSet, &'static IndexHeader)> {
    let (p, minimizers, header) = INDEX.get_or_init(|| {
        let (m, h) = load_minimizers(path).unwrap();
        (path.to_owned(), m, h)
    });
    assert_eq!(
        p, path,
        "Currently, the server can only have one index loaded."
    );

    Ok((minimizers, header))
}

/// Load minimizers from an index file
pub fn load_minimizers(path: &Path) -> Result<(crate::MinimizerSet, IndexHeader)> {
    let file = File::open(path).context(format!("Failed to open index file {:?}", path))?;
    let mut reader = BufReader::with_capacity(1 << 20, file);
    let config = bincode::config::standard().with_fixed_int_encoding();

    // Deserialise header
    let header: IndexHeader =
        decode_from_std_read(&mut reader, config).context("Failed to deserialise index header")?;
    header.validate()?;

    // Deserialise the count of minimizers
    let count: usize = decode_from_std_read(&mut reader, config)
        .context("Failed to deserialise minimizer count")?;

    let minimizers = if header.kmer_length <= 32 {
        // Read as u64 (8 bytes per minimizer) - zero-cost abstraction
        let mut set = RapidHashSet::<u64>::with_capacity_and_hasher(count, FixedRapidHasher);
        const B: usize = 16 * 1024;
        let mut buffer = vec![0u8; 8 * B];
        for i in (0..count).step_by(B) {
            let batch_count = B.min(count - i);
            let batch = &mut buffer[..8 * batch_count];
            reader.read_exact(batch).unwrap();
            for bytes in batch.as_chunks::<8>().0 {
                set.insert(u64::from_le_bytes(*bytes));
            }
        }
        crate::MinimizerSet::U64(set)
    } else {
        // Read as u128 (16 bytes per minimizer) - zero-cost abstraction
        let mut set = RapidHashSet::<u128>::with_capacity_and_hasher(count, FixedRapidHasher);
        const B: usize = 16 * 1024;
        let mut buffer = vec![0u8; 16 * B];
        for i in (0..count).step_by(B) {
            let batch_count = B.min(count - i);
            let batch = &mut buffer[..16 * batch_count];
            reader.read_exact(batch).unwrap();
            for bytes in batch.as_chunks::<16>().0 {
                set.insert(u128::from_le_bytes(*bytes));
            }
        }
        crate::MinimizerSet::U128(set)
    };

    Ok((minimizers, header))
}

/// Helper function to write minimizers to output file or stdout
pub fn dump_minimizers(
    minimizers: &crate::MinimizerSet,
    header: &IndexHeader,
    output_path: Option<&Path>,
) -> Result<()> {
    // Create writer based on output path
    let writer: Box<dyn Write> = if let Some(path) = output_path {
        if path.as_os_str() == "-" {
            Box::new(BufWriter::new(io::stdout()))
        } else {
            Box::new(BufWriter::new(
                File::create(path).context("Failed to create output file")?,
            ))
        }
    } else {
        Box::new(BufWriter::new(io::stdout()))
    };

    // Serialise header and minimizers
    let mut writer = BufWriter::new(writer);
    // Use fixed-width little-endian encoding for all values.
    let config = bincode::config::standard().with_fixed_int_encoding();
    encode_into_std_write(header, &mut writer, config)
        .context("Failed to serialise index header")?;

    // Serialise the count of minimizers first
    let count = minimizers.len();
    encode_into_std_write(count, &mut writer, config)
        .context("Failed to serialise minimizer count")?;

    // Serialise each minimizer based on variant
    match minimizers {
        crate::MinimizerSet::U64(set) => {
            for &val in set {
                encode_into_std_write(val, &mut writer, config)
                    .context("Failed to serialise minimizer")?;
            }
        }
        crate::MinimizerSet::U128(set) => {
            for &val in set {
                encode_into_std_write(val, &mut writer, config)
                    .context("Failed to serialise minimizer")?;
            }
        }
    }
    Ok(())
}

fn reader_with_inferred_batch_size(
    in_path: Option<&Path>,
) -> Result<paraseq::fastx::Reader<Box<dyn Read + Send>>> {
    let mut reader = paraseq::fastx::Reader::from_optional_path(in_path).unwrap();
    reader.update_batch_size_in_bp(256 * 1024)?;
    Ok(reader)
}

#[derive(Clone)]
struct BuildIndexProcessor<'c> {
    config: &'c IndexConfig,
    hasher: KmerHasher,
    // Local buffers
    buffers: Buffers,
    local_stats: ProcessingStats,
    local_minimizers_u64: Option<RapidHashSet<u64>>,
    local_minimizers_u128: Option<RapidHashSet<u128>>,
    local_record_info: Vec<(Vec<u8>, usize)>, // (record_id, seq_len) for progress output
    // Global state
    global_stats: Arc<Mutex<ProcessingStats>>,
    global_minimizers_u64: Arc<Mutex<Option<RapidHashSet<u64>>>>,
    global_minimizers_u128: Arc<Mutex<Option<RapidHashSet<u128>>>>,
}

impl<Rf: Record> ParallelProcessor<Rf> for BuildIndexProcessor<'_> {
    fn process_record(&mut self, record: Rf) -> paraseq::parallel::Result<()> {
        let seq = record.seq();
        self.local_stats.total_seqs += 1;
        self.local_stats.total_bp += seq.len() as u64;

        crate::minimizers::fill_minimizers(
            &seq,
            &self.hasher,
            self.config.kmer_length,
            self.config.window_size,
            self.config.entropy_threshold,
            &mut self.buffers,
        );

        // Extend appropriate local set based on type
        match &mut self.buffers.minimizers {
            crate::MinimizerVec::U64(vec) => {
                self.local_minimizers_u64
                    .as_mut()
                    .unwrap()
                    .extend(vec.iter());
            }
            crate::MinimizerVec::U128(vec) => {
                self.local_minimizers_u128
                    .as_mut()
                    .unwrap()
                    .extend(vec.iter());
            }
        }

        // Store record info for progress output (printed sequentially in on_batch_complete)
        if !self.config.quiet {
            self.local_record_info
                .push((record.id().to_vec(), seq.len()));
        }

        Ok(())
    }

    fn on_batch_complete(&mut self) -> paraseq::parallel::Result<()> {
        // Merge local minimizers into global set and get new total count
        let minimizer_count = if let Some(local) = &mut self.local_minimizers_u64 {
            let mut global = self.global_minimizers_u64.lock();
            global.as_mut().unwrap().extend(local.iter());
            local.clear();
            global.as_ref().unwrap().len()
        } else {
            let mut global = self.global_minimizers_u128.lock();
            global
                .as_mut()
                .unwrap()
                .extend(self.local_minimizers_u128.as_ref().unwrap().iter());
            self.local_minimizers_u128.as_mut().unwrap().clear();
            global.as_ref().unwrap().len()
        };

        // Update global stats
        {
            let mut stats = self.global_stats.lock();
            stats.total_seqs += self.local_stats.total_seqs;
            stats.total_bp += self.local_stats.total_bp;
            self.local_stats = ProcessingStats::default();
        }

        // Print progress for each record in this batch (sequentially, after merging)
        if !self.config.quiet {
            for (record_id, seq_len) in &self.local_record_info {
                let id_str = std::str::from_utf8(record_id).unwrap_or("unknown");
                eprintln!(
                    "  {} ({}bp), total minimizers: {}",
                    id_str, seq_len, minimizer_count
                );
            }
            self.local_record_info.clear();
        }

        Ok(())
    }
}

/// Build an index of minimizers from a fastx file
pub fn build(config: &IndexConfig) -> Result<()> {
    let start_time = Instant::now();
    let path = &config.input_path;

    let version: String = env!("CARGO_PKG_VERSION").to_string();

    // Build options string similar to filter
    let mut options = Vec::<String>::new();
    if config.threads > 0 {
        options.push(format!("threads={}", config.threads));
    }

    eprintln!(
        "Deacon v{}; mode: build; input: single; options: {}",
        version,
        options.join(", ")
    );

    // Ensure k <= 57 for u128 k-mer storage
    if config.kmer_length > 57 {
        return Err(anyhow::anyhow!(
            "k-mer length must be <= 57 (k={})",
            config.kmer_length
        ));
    }

    // Ensure l = k + w - 1 is odd so that canonicalisation tie breaks work correctly
    let l = config.kmer_length as usize + config.window_size as usize - 1;
    if l % 2 == 0 {
        return Err(anyhow::anyhow!(
            "Constraint violated: k + w - 1 must be odd (k={}, w={})",
            config.kmer_length,
            config.window_size
        ));
    }

    let in_path = if path.as_os_str() == "-" {
        None
    } else {
        Some(path.as_path())
    };
    let reader = reader_with_inferred_batch_size(in_path)?;

    eprintln!(
        "Building index (k={}, w={})",
        config.kmer_length, config.window_size
    );

    let mut processor = if config.kmer_length <= 32 {
        BuildIndexProcessor {
            config,
            hasher: KmerHasher::new(config.kmer_length as usize),
            local_stats: ProcessingStats::default(),
            buffers: Buffers::new_u64(),
            local_minimizers_u64: Some(RapidHashSet::default()),
            local_minimizers_u128: None,
            local_record_info: Vec::new(),
            global_stats: Arc::new(Mutex::new(ProcessingStats::default())),
            global_minimizers_u64: Arc::new(Mutex::new(Some(RapidHashSet::default()))),
            global_minimizers_u128: Arc::new(Mutex::new(None)),
        }
    } else {
        BuildIndexProcessor {
            config,
            hasher: KmerHasher::new(config.kmer_length as usize),
            local_stats: ProcessingStats::default(),
            buffers: Buffers::new_u128(),
            local_minimizers_u64: None,
            local_minimizers_u128: Some(RapidHashSet::default()),
            local_record_info: Vec::new(),
            global_stats: Arc::new(Mutex::new(ProcessingStats::default())),
            global_minimizers_u64: Arc::new(Mutex::new(None)),
            global_minimizers_u128: Arc::new(Mutex::new(Some(RapidHashSet::default()))),
        }
    };
    reader.process_parallel(&mut processor, config.threads)?;

    let all_minimizers = if config.kmer_length <= 32 {
        let set = Arc::try_unwrap(processor.global_minimizers_u64)
            .unwrap()
            .into_inner()
            .unwrap();
        crate::MinimizerSet::U64(set)
    } else {
        let set = Arc::try_unwrap(processor.global_minimizers_u128)
            .unwrap()
            .into_inner()
            .unwrap();
        crate::MinimizerSet::U128(set)
    };
    let stats = Arc::try_unwrap(processor.global_stats)
        .unwrap()
        .into_inner();

    eprintln!(
        "Indexed {} minimizers from {} record(s) ({}bp)",
        all_minimizers.len(),
        stats.total_seqs,
        stats.total_bp
    );

    let header = IndexHeader::new(config.kmer_length, config.window_size);

    // Write to output path or stdout
    dump_minimizers(&all_minimizers, &header, config.output_path.as_deref())?;

    let total_time = start_time.elapsed();
    eprintln!("Completed in {:.2?}", total_time);

    Ok(())
}

#[derive(Clone)]
struct DiffIndexProcessor {
    kmer_length: u8,
    window_size: u8,
    hasher: KmerHasher,
    // Local buffers
    buffers: Buffers,
    local_stats: ProcessingStats,
    local_minimizers_u64: Option<RapidHashSet<u64>>,
    local_minimizers_u128: Option<RapidHashSet<u128>>,
    // Global state
    global_stats: Arc<Mutex<ProcessingStats>>,
    initial_size: usize,
    global_minimizers_u64: Arc<Mutex<Option<RapidHashSet<u64>>>>,
    global_minimizers_u128: Arc<Mutex<Option<RapidHashSet<u128>>>>,
}

impl<Rf: Record> ParallelProcessor<Rf> for DiffIndexProcessor {
    fn process_record(&mut self, record: Rf) -> paraseq::parallel::Result<()> {
        let seq = record.seq();
        self.local_stats.total_seqs += 1;
        self.local_stats.total_bp += seq.len() as u64;

        crate::minimizers::fill_minimizers(
            &seq,
            &self.hasher,
            self.kmer_length,
            self.window_size,
            0.0,
            &mut self.buffers,
        );

        // Extend appropriate local set based on type
        match &mut self.buffers.minimizers {
            crate::MinimizerVec::U64(vec) => {
                self.local_minimizers_u64
                    .as_mut()
                    .unwrap()
                    .extend(vec.iter());
            }
            crate::MinimizerVec::U128(vec) => {
                self.local_minimizers_u128
                    .as_mut()
                    .unwrap()
                    .extend(vec.iter());
            }
        }

        Ok(())
    }

    fn on_batch_complete(&mut self) -> paraseq::parallel::Result<()> {
        // Write buffer to output
        let len = if let Some(local) = &mut self.local_minimizers_u64 {
            let mut global = self.global_minimizers_u64.lock();
            let global_set = global.as_mut().unwrap();
            for &minimizer in local.iter() {
                global_set.remove(&minimizer);
            }
            let len = global_set.len();
            local.clear();
            len
        } else {
            let mut global = self.global_minimizers_u128.lock();
            let global_set = global.as_mut().unwrap();
            for &minimizer in self.local_minimizers_u128.as_ref().unwrap().iter() {
                global_set.remove(&minimizer);
            }
            let len = global_set.len();
            self.local_minimizers_u128.as_mut().unwrap().clear();
            len
        };

        // Update global stats
        {
            let mut stats = self.global_stats.lock();
            stats.total_seqs += self.local_stats.total_seqs;
            stats.total_bp += self.local_stats.total_bp;

            let current_gb = stats.total_bp / 1_000_000_000;
            if current_gb > stats.last_reported {
                eprintln!(
                    "  Processed {} sequences ({}bp), removed {} minimizers",
                    stats.total_seqs,
                    stats.total_bp,
                    self.initial_size - len
                );
                stats.last_reported = current_gb;
            }

            self.local_stats = ProcessingStats::default();
        }

        Ok(())
    }
}

/// Stream minimizers from a FASTX file or stdin and remove those present in first_minimizers
fn stream_diff_fastx(
    fastx_path: &Path,
    kmer_length: u8,
    window_size: u8,
    first_header: &IndexHeader,
    threads: usize,
    first_minimizers: &mut crate::MinimizerSet,
) -> Result<(usize, usize)> {
    let path = fastx_path;

    // Ensure k <= 57 for u128 k-mer storage
    if kmer_length > 57 {
        return Err(anyhow::anyhow!(
            "k-mer length must be <= 57 (k={})",
            kmer_length
        ));
    }

    // Validate parameters match the first index
    if kmer_length != first_header.kmer_length() || window_size != first_header.window_size() {
        return Err(anyhow::anyhow!(
            "FASTX parameters (k={}, w={}) must match first index (k={}, w={})",
            kmer_length,
            window_size,
            first_header.kmer_length(),
            first_header.window_size()
        ));
    }

    if path.as_os_str() == "-" {
        eprintln!(
            "Second index: processing FASTX from stdin (k={}, w={})…",
            kmer_length, window_size
        );
    } else {
        eprintln!(
            "Second index: processing FASTX from file (k={}, w={})…",
            kmer_length, window_size
        );
    }

    let in_path = if path.as_os_str() == "-" {
        None
    } else {
        Some(path)
    };

    let reader = reader_with_inferred_batch_size(in_path)?;

    // Move first_minimizers into Arc<Mutex<>> for parallel access
    let initial_size = first_minimizers.len();
    let (mut processor, global_minimizers_u64, global_minimizers_u128) = match first_minimizers {
        crate::MinimizerSet::U64(set) => {
            let moved_set = std::mem::take(set);
            let arc = Arc::new(Mutex::new(Some(moved_set)));
            (
                DiffIndexProcessor {
                    kmer_length,
                    window_size,
                    hasher: KmerHasher::new(kmer_length as usize),
                    local_stats: ProcessingStats::default(),
                    buffers: Buffers::new_u64(),
                    local_minimizers_u64: Some(RapidHashSet::default()),
                    local_minimizers_u128: None,
                    global_stats: Arc::new(Mutex::new(ProcessingStats::default())),
                    initial_size,
                    global_minimizers_u64: arc.clone(),
                    global_minimizers_u128: Arc::new(Mutex::new(None)),
                },
                Some(arc),
                None,
            )
        }
        crate::MinimizerSet::U128(set) => {
            let moved_set = std::mem::take(set);
            let arc = Arc::new(Mutex::new(Some(moved_set)));
            (
                DiffIndexProcessor {
                    kmer_length,
                    window_size,
                    hasher: KmerHasher::new(kmer_length as usize),
                    local_stats: ProcessingStats::default(),
                    buffers: Buffers::new_u128(),
                    local_minimizers_u64: None,
                    local_minimizers_u128: Some(RapidHashSet::default()),
                    global_stats: Arc::new(Mutex::new(ProcessingStats::default())),
                    initial_size,
                    global_minimizers_u64: Arc::new(Mutex::new(None)),
                    global_minimizers_u128: arc.clone(),
                },
                None,
                Some(arc),
            )
        }
    };

    reader.process_parallel(&mut processor, threads)?;

    // Extract results from Arc<Mutex<>> after processing completes
    let stats = processor.global_stats.lock().clone();
    *first_minimizers = if let Some(arc) = global_minimizers_u64 {
        let set = arc.lock().take().unwrap();
        crate::MinimizerSet::U64(set)
    } else {
        let set = global_minimizers_u128.unwrap().lock().take().unwrap();
        crate::MinimizerSet::U128(set)
    };

    eprintln!(
        "Processed {} sequences ({}bp) from FASTX file",
        stats.total_seqs, stats.total_bp
    );

    Ok((stats.total_seqs as usize, stats.total_bp as usize))
}

/// Compute the set difference between two minimizer indexes (A - B)
pub fn diff(
    first: &Path,
    second: &Path,
    kmer_length: Option<u8>,
    window_size: Option<u8>,
    threads: usize,
    output: Option<&Path>,
) -> Result<()> {
    let start_time = Instant::now();

    // Load first file (always an index)
    let (mut first_minimizers, header) = load_minimizers(first)?;
    eprintln!("First index: loaded {} minimizers", first_minimizers.len());

    // Guess if second file is an index or FASTX file
    let second_minimizers = if let (Some(k), Some(w)) = (kmer_length, window_size) {
        // Second file is a FASTX file - stream diff with provided k, w
        let before_count = first_minimizers.len();
        let (_seq_count, _total_bp) =
            stream_diff_fastx(second, k, w, &header, threads, &mut first_minimizers)?;

        // Report results
        eprintln!(
            "Removed {} minimizers, {} remaining",
            before_count - first_minimizers.len(),
            first_minimizers.len()
        );

        dump_minimizers(&first_minimizers, &header, output)?;

        let total_time = start_time.elapsed();
        eprintln!("Completed difference operation in {:.2?}", total_time);

        return Ok(());
    } else {
        // Try to load as index file first
        if let Ok((second_minimizers, second_header)) = load_minimizers(&second) {
            // Second file is an index file
            eprintln!(
                "Second index: loaded {} minimizers",
                second_minimizers.len()
            );

            // Validate compatible headers
            if second_header.kmer_length() != header.kmer_length()
                || second_header.window_size() != header.window_size()
            {
                return Err(anyhow::anyhow!(
                    "Incompatible headers: second index has k={}, w={}, but first index has k={}, w={}",
                    second_header.kmer_length(),
                    second_header.window_size(),
                    header.kmer_length(),
                    header.window_size()
                ));
            }

            second_minimizers
        } else {
            // Second file is not a valid index, treat as FASTX file
            // Use k and w from first index header and do a streaming diff
            let k = header.kmer_length();
            let w = header.window_size();

            // Count minimizers before diff
            let before_count = first_minimizers.len();

            let (_seq_count, _total_bp) =
                stream_diff_fastx(&second, k, w, &header, threads, &mut first_minimizers)?;

            // Report results
            eprintln!(
                "Removed {} minimizers, {} remaining",
                before_count - first_minimizers.len(),
                first_minimizers.len()
            );

            dump_minimizers(&first_minimizers, &header, output)?;

            let total_time = start_time.elapsed();
            eprintln!("Completed difference operation in {:.2?}", total_time);

            return Ok(());
        }
    };

    // Handle straightforward index-to-index diffing
    // Count minimizers before diff
    let before_count = first_minimizers.len();

    // Remove all minimizers in second_minimizers from first_minimizers
    first_minimizers.remove_all(&second_minimizers);

    // Report results
    eprintln!(
        "Removed {} minimizers, {} remaining",
        before_count - first_minimizers.len(),
        first_minimizers.len()
    );

    dump_minimizers(&first_minimizers, &header, output)?;

    let total_time = start_time.elapsed();
    eprintln!("Completed diff operation in {:.2?}", total_time);

    Ok(())
}

/// Show info about an index
pub fn info(index_path: &Path) -> Result<()> {
    let start_time = Instant::now();

    // Load index file
    let (minimizers, header) = load_minimizers(index_path)?;

    // Show index info
    eprintln!("Index information:");
    eprintln!("  Format version: {}", header.format_version);
    eprintln!("  K-mer length (k): {}", header.kmer_length());
    eprintln!("  Window size (w): {}", header.window_size());
    eprintln!("  Distinct minimizer count: {}", minimizers.len());

    let total_time = start_time.elapsed();
    eprintln!("Loaded index info in {:.2?}", total_time);

    Ok(())
}

/// Combine minimizer indexes (set union)
pub fn union(inputs: &[PathBuf], output: Option<&Path>) -> Result<()> {
    let start_time = Instant::now();
    // Check input files
    if inputs.is_empty() {
        return Err(anyhow::anyhow!(
            "No input files provided for union operation"
        ));
    }

    // Read all headers first to determine total capacity needed
    let mut headers_and_counts = Vec::new();

    for path in inputs {
        let (header, count) = load_header_and_count(path)?;
        headers_and_counts.push((header, count));
    }

    // Get header from first file for output
    let header = &headers_and_counts[0].0;

    eprintln!(
        "Performing union of indexes (k={}, w={})",
        header.kmer_length(),
        header.window_size()
    );

    // Verify all headers are compatible
    for (i, (file_header, _)) in headers_and_counts.iter().enumerate() {
        if file_header.kmer_length() != header.kmer_length()
            || file_header.window_size() != header.window_size()
        {
            return Err(anyhow::anyhow!(
                "Incompatible headers: index {} has k={}, w={}, but first index has k={}, w={}",
                i,
                file_header.kmer_length(),
                file_header.window_size(),
                header.kmer_length(),
                header.window_size()
            ));
        }
    }

    // Load first index to determine type (u64 vs u128)
    let (mut all_minimizers, _) = load_minimizers(&inputs[0])?;
    eprintln!("Index 1: loaded {} minimizers", all_minimizers.len());

    // Now load and merge remaining indexes
    for (i, path) in inputs.iter().enumerate().skip(1) {
        let (minimizers, _) = load_minimizers(path)?;
        let before_count = all_minimizers.len();

        // Merge minimizers (set union)
        all_minimizers.extend(minimizers);

        let expected_count = headers_and_counts[i].1;
        eprintln!(
            "Index {}: expected {} minimizers, added {} new, total: {}",
            i + 1,
            expected_count,
            all_minimizers.len() - before_count,
            all_minimizers.len()
        );
    }

    dump_minimizers(&all_minimizers, header, output)?;

    let total_time = start_time.elapsed();
    eprintln!(
        "United {} indexes with {} total minimizers in {:.2?}",
        inputs.len(),
        all_minimizers.len(),
        total_time
    );

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_header_creation() {
        let header = IndexHeader::new(31, 21);

        assert_eq!(header.format_version, 3);
        assert_eq!(header.kmer_length(), 31);
        assert_eq!(header.window_size(), 21);
    }

    #[test]
    fn test_header_validation() {
        // Valid header (v3 only)
        let valid_header_v3 = IndexHeader {
            format_version: 3,
            kmer_length: 31,
            window_size: 21,
        };
        assert!(valid_header_v3.validate().is_ok());

        // Invalid format versions
        let invalid_header_v1 = IndexHeader {
            format_version: 1,
            kmer_length: 31,
            window_size: 21,
        };
        assert!(invalid_header_v1.validate().is_err());

        let invalid_header_v2 = IndexHeader {
            format_version: 2,
            kmer_length: 31,
            window_size: 21,
        };
        assert!(invalid_header_v2.validate().is_err());

        let invalid_header_v4 = IndexHeader {
            format_version: 4,
            kmer_length: 31,
            window_size: 21,
        };
        assert!(invalid_header_v4.validate().is_err());
    }
}
